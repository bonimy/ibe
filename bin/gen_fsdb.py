#! /usr/bin/env python
import contextlib
import csv
import datetime
import optparse
import os
import subprocess
import sys

dialect = {
    'skipinitialspace': False,
    'doublequote': False,
    'escapechar': '\\',
    'delimiter': '|',
    'quotechar': '"',
    'lineterminator' : '\n',
    'quoting': csv.QUOTE_NONE
}

class Path(object):
    def __init__(self, path_id, parent_path_id, group_id, min_pub_date, file_name, is_dir):
        self.path_id = path_id
        self.parent_path_id = parent_path_id
        self.group_ids= set()
        self.group_ids.add(group_id)
        self.min_pub_date = min_pub_date
        self.file_name = file_name
        self.is_dir = int(is_dir)

    def update(self, group_id, pub_date):
        self.group_ids.add(group_id)
        self.min_pub_date = min(self.min_pub_date, pub_date)

    def write_to(self, writer):
        writer.writerow((
            self.parent_path_id,
            self.path_id,
            self.min_pub_date,
            self.file_name,
            self.is_dir,
        ))

    def write_groups_to(self, writer):
        for g in self.group_ids:
            writer.writerow((self.path_id, g))


def gen_fsdb_tables(scratch_dir, f):
    """Reads sorted (path, group_id, pub_date) records from standard input,
    and writes out derived data to 3 bar delimited files:

    File                          Fields
    ----                          ------
    <scratch_dir>/paths.bar       path_id, path
    <scratch_dir>/hierarchy.bar   parent_path_id, path_id, min_pub_date, file_name, is_dir
    <scratch_dir>/groups.bar      path_id, group_id
    """
    prev_path = None
    path_id = None
    stack = []
    reader = csv.reader(f, **dialect)
    with contextlib.nested(
        open(os.path.join(scratch_dir, 'paths.bar'), 'wb'),
        open(os.path.join(scratch_dir, 'hierarchy.bar'), 'wb'),
        open(os.path.join(scratch_dir, 'groups.bar'), 'wb')
    ) as (pf, hf, gf):
        pw, hw, gw = map(lambda x: csv.writer(x, **dialect), (pf, hf, gf))
        for row in reader:
            path = os.path.normpath(row[0])        # eliminate double/trailing slashes
            path = os.path.join(os.path.sep, path) # ensure there is a leading /
            group_id = int(row[1])
            try:
                 pub_date = datetime.datetime.strptime(row[2], '%Y-%m-%d %H:%M:%S')
            except ValueError:
                 pub_date = datetime.datetime.strptime(row[2], '%Y-%m-%d %H:%M:%S.%f')
            components = path.split(os.path.sep)
            if path_id is None:
                # write out initial (path_id, path) pairs, build Path stack
                for i, c in enumerate(components):
                    pw.writerow([i + 1, os.path.join(*components[:i + 1])])
                    stack.append(Path(i + 1, i,
                        group_id, pub_date, c, i != len(components) - 1))
                path_id = len(components) + 1
                prev_path = path
            elif path == prev_path:
                # update Path stack with security attributes 
                map(lambda x: x.update(group_id, pub_date), stack)
            else:
                assert prev_path < path               # input must be sorted
                assert not path.startswith(prev_path) # input path cannot be a directory
                # find shared prefix of path and prev_path
                for j in xrange(min(len(components), len(stack))):
                    if components[j] != stack[j].file_name:
                        break
                assert j > 0                          # every input path has a common root
                # write out and discard paths that are not shared
                for p in stack[j:]:
                    p.write_to(hw)
                    p.write_groups_to(gw)
                del stack[j:]
                # update security attributes for shared paths
                map(lambda x: x.update(group_id, pub_date), stack)
                # generate new Path objects
                for i, c in enumerate(components[j:]):
                    pw.writerow([path_id + i, os.path.join(*components[:j + i + 1])])
                    parent_path_id = stack[j + i - 1].path_id
                    stack.append(Path(path_id + i, parent_path_id,
                        group_id, pub_date, c, i != len(components) - j - 1))
                path_id += len(components) - j
                prev_path = path
        # write out remaining paths
        for p in stack:
            p.write_to(hw)
            p.write_groups_to(gw)


def sort_fsdb_tables(scratch_dir):
    """Sort files generated by gen_fsdb_tables. This is intended to increase
    data locality when querying the file-system metadata database later.
    In particular, all Hierarchy table entries sharing a common parent
    directory will be colocated.
    """
    h = os.path.join(scratch_dir, 'hierarchy.bar')
    g = os.path.join(scratch_dir, 'groups.bar')
    # Make sure UNIX sort and python string comparisons agree
    env = os.environ.copy()
    env['LC_COLLATE'] = 'C'
    subprocess.check_call(
        ['sort', '-t', '|', '-k', '1,1n', '-k', '2,2n', '-o', h + '.sorted', h],
        shell=False, env=env)
    subprocess.check_call(
        ['sort', '-t', '|', '-k', '1,1n', '-k', '2,2n', '-o', g + '.sorted', g],
        shell=False, env=env)


def create_fsdb(scratch_dir, fsdb):
    sql = os.path.join(scratch_dir, 'create_fsdb.sql')
    with open(sql, 'wb') as f:
        f.write(str.format("""
PRAGMA synchronous = 0;
PRAGMA journal_mode = OFF;
PRAGMA page_size = 4096;

CREATE TABLE Paths (
    path_id INTEGER      NOT NULL PRIMARY KEY,
    path    VARCHAR(255) NOT NULL UNIQUE
);

CREATE TABLE Groups (
    path_id  INTEGER NOT NULL REFERENCES Paths (path_id),
    group_id INTEGER NOT NULL,
    UNIQUE (path_id, group_id)
);

CREATE TABLE Hierarchy (
    parent_path_id INTEGER      NOT NULL,
    path_id        INTEGER      NOT NULL UNIQUE REFERENCES Paths (path_id),
    min_pub_date   DATETIME     NOT NULL,
    file_name      VARCHAR(255) NOT NULL,
    is_dir         INTEGER      NOT NULL
);

.separator '|'
.import {scratch_dir}/paths.bar Paths
.import {scratch_dir}/groups.bar.sorted Groups
.import {scratch_dir}/hierarchy.bar.sorted Hierarchy

CREATE INDEX Hierarchy_parent_path_id ON Hierarchy (parent_path_id);
""", scratch_dir=scratch_dir))
    subprocess.check_call([
        'sqlite3', '-init', sql, fsdb,
        "SELECT 'Processed ' || CAST(COUNT(*) AS TEXT) || ' paths' FROM Paths"], shell=False)


def main():
    parser = optparse.OptionParser("""
        %prog [options]

        Reads sorted (path, group_id, pub_date) records from a file or standard
        input, and builds a corresponding file system metadata SQLite database
        that can be used to check file access permission or for security aware
        directory listings.
        """)
    parser.add_option(
        '-s', '--scratch-dir', type='string', dest='scratch_dir',
        default=os.environ.get('TMPDIR', '/tmp'),
        help='Scratch directory name; defaults to $TMPDIR and falls back to /tmp (%default)')
    parser.add_option(
        '-o', '--output', type='string', dest='fsdb', default='fsdb.sqlite3',
        help='Name of SQLite database file to generate; defaults to %default')
    parser.add_option(
        '-i', '--input', type='string', dest='input',
        help='Input file name. If unspecified, read from standard input')
    ns, inputs = parser.parse_args()
    if len(inputs) != 0:
        parser.error('Unrecognized arguments')
    if ns.input:
        with open(ns.input, 'rb') as f:
            gen_fsdb_tables(ns.scratch_dir, f)
    else:
        gen_fsdb_tables(ns.scratch_dir, sys.stdin)
    sort_fsdb_tables(ns.scratch_dir)
    create_fsdb(ns.scratch_dir, ns.fsdb)


if __name__ == "__main__":
    main()
